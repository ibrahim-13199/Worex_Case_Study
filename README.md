# Worex_Case_Study
Some function implemented in Pyspark for big data case study. 
-------------------------------------------------------------
1. Data Preprocessing: Load and preprocess the dataset using Spark. Perform necessary data
cleaning, filtering, and transformation operations as required.
2. Data Analysis: Implement at least three meaningful data analysis tasks using Spark's core
functionalities. This can include but is not limited to:
- Aggregations
- Joins
- Filtering
- Sorting
- Grouping
3. Performance Optimization: Optimize the Spark application for performance by considering
techniques such as:
- Caching and persisting RDDs/DataFrames
- Parallelization
- Broadcast joins
- Partitioning
- Memory management
